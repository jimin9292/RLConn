{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0410 11:30:17.712868 4720741824 deprecation_wrapper.py:119] From /Users/Frank/github/RLConn/RLConn/control_dqn.py:5: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "W0410 11:30:17.732421 4720741824 deprecation_wrapper.py:119] From /Users/Frank/github/RLConn/RLConn/control_dqn.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0410 11:30:17.740344 4720741824 deprecation_wrapper.py:119] From /Users/Frank/github/RLConn/RLConn/control_dqn.py:66: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0410 11:30:17.741391 4720741824 deprecation.py:323] From /Users/Frank/github/RLConn/RLConn/control_dqn.py:68: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0410 11:30:18.165222 4720741824 deprecation_wrapper.py:119] From /Users/Frank/github/RLConn/RLConn/control_dqn.py:94: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "W0410 11:30:18.172076 4720741824 deprecation_wrapper.py:119] From /Users/Frank/github/RLConn/RLConn/control_dqn.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0410 11:30:18.468187 4720741824 deprecation_wrapper.py:119] From /Users/Frank/github/RLConn/RLConn/control_dqn.py:41: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "default_dir = os.path.dirname(os.getcwd())\n",
    "os.chdir(default_dir)\n",
    "\n",
    "import RLConn as rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_connectome(N):\n",
    "    l = int(N*(N-1)/2)\n",
    "    Gg = np.zeros((N,N))\n",
    "    Gg[np.logical_not(np.tri(N,dtype=bool))] = np.random.randint(0,10,l)\n",
    "    Gg += Gg.T\n",
    "    Gs = np.zeros((N,N))\n",
    "    Gs[np.tri(N,dtype=bool,k=-1)] = np.random.rand(l)\n",
    "    Gs[np.logical_not(np.tri(N,dtype=bool))] = np.random.randint(0,10,l)\n",
    "    return Gg, Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observe(Gg, Gs):\n",
    "    N = Gg.shape[0]\n",
    "    return np.concatenate((Gg[np.triu_indices(N,k=1)],Gs[np.triu_indices(N,k=1)],Gs[np.tril_indices(N,k=-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(Gg, Gs, action, location, dx = 0.1):\n",
    "    N = Gg.shape[0]\n",
    "    size = int(N*(N-1)/2)\n",
    "    change = dx*(action == 0) + (-dx)*(action == 2)\n",
    "    if location < size:\n",
    "        coordinate = np.array(np.triu_indices(N,k=1)).T[location]\n",
    "        Gg[coordinate[0], coordinate[1]] += change\n",
    "        Gg[coordinate[1], coordinate[0]] += change\n",
    "    elif location < 2*size:\n",
    "        coordinate = np.array(np.triu_indices(N,k=1)).T[location - size]\n",
    "        Gs[coordinate[0], coordinate[1]] += change\n",
    "    else: \n",
    "        coordinate = np.array(np.tril_indices(N,k=-1)).T[location - 2*size]\n",
    "        Gs[coordinate[0], coordinate[1]] += change\n",
    "    return Gg, Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_action(N):\n",
    "    size = int(N*(N-1)/2)\n",
    "    return np.random.randint(2), np.random.randint(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_x(x, Gg, Gs, reward):\n",
    "    obs = get_observe(Gg, Gs)\n",
    "    x = np.concatenate((x[len(obs)+1:], obs))\n",
    "    x = np.append(x,reward)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "N = 3\n",
    "size = int(3*N*(N-1)/2)\n",
    "PG = rc.alpg.ActLocPolicyGradient(\n",
    "    n_actions=3,\n",
    "    n_features=(size+1)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'RLConn.utils' has no attribute 'scorer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f50d640d8d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mGg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_connectome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_observe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'RLConn.utils' has no attribute 'scorer'"
     ]
    }
   ],
   "source": [
    "for i_episode in range(3000):\n",
    "    #initialize x\n",
    "    x = np.array([])\n",
    "    Gg, Gs = get_random_connectome(N)\n",
    "    reward = -rc.utils.scorer(Gg, Gs)\n",
    "    x = np.concatenate((x, get_observe(Gg, Gs)))\n",
    "    x = np.append(x,reward)\n",
    "    for i in range(9):\n",
    "        action, location = get_rand_action(N)\n",
    "        Gg, Gs = move(Gg, Gs, action, location, dx=0.1)\n",
    "        reward = -rc.utils.scorer(Gg, Gs)\n",
    "        x = np.concatenate((x, get_observe(Gg, Gs)))\n",
    "        x = np.append(x,reward)   \n",
    "    print(len(x))\n",
    "    \n",
    "    #choose action using nn\n",
    "    for step in range(300):\n",
    "        action, location = PG.choose_action(x)\n",
    "        Gg, Gs = move(Gg, Gs, action, location, dx=0.1)\n",
    "        reward = -rc.utils.scorer(Gg, Gs)\n",
    "        PG.store_transition(x, action, location, reward)\n",
    "        x = update_x(x, Gg, Gs, reward)\n",
    "        print(len(x))\n",
    "    ep_rs_sum = sum(RL.ep_rs)\n",
    "    if 'running_reward' not in globals():\n",
    "        running_reward = ep_rs_sum\n",
    "    else:\n",
    "        running_reward = running_reward * 0.99 + ep_rs_sum * 0.01\n",
    "    print(\"episode:\", i_episode, \"  reward:\", int(running_reward))\n",
    "    print(\"Gg:\", Gg.flatten(), \"  Gs:\", Gs.flatten())\n",
    "    vt = PG.learn()\n",
    "    # print(vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
